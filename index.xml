<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>My New Hugo Site</title><link>http://example.org/</link><description>Recent content on My New Hugo Site</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 23 Jul 2023 18:41:00 -0700</lastBuildDate><atom:link href="http://example.org/index.xml" rel="self" type="application/rss+xml"/><item><title>Hello World</title><link>http://example.org/blog/hello-world/</link><pubDate>Sun, 23 Jul 2023 18:41:00 -0700</pubDate><guid>http://example.org/blog/hello-world/</guid><description>I&amp;rsquo;ve been interested in the idea of &amp;lsquo;active externalism&amp;rsquo; - in (very) rough terms, that an individual&amp;rsquo;s mental states (hopes, fears, desires) are not fully contained within themselves &amp;amp; their mind.1
A simple example would be storing your thoughts in a notebook, and retrieving them later.
After learning about the capabilities of LLMs and similar technology, my immediate thought was to use those systems to extend the bounds of the human brain.</description></item></channel></rss>